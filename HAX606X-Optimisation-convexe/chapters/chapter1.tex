% txs:///compile | txs:///view-pdf-internal --embedded | cmd /c move /Y output\%.pdf pdfs\
% pdflatex -synctex=1 -interaction=nonstopmode -output-directory=output %.tex
% pdflatex -synctex=1 -output-directory=output chapter1.tex && move /Y output\chapter1.pdf .\
\documentclass[french,a4paper,10pt]{article}
\input{../../common/header.tex}
\usepackage[a4paper,hmargin=30mm,vmargin=30mm]{geometry}
\title{\color{astral} \sffamily \bfseries Optimisation Convexe}
\author{Ivan Lejeune\thanks{Cours inspiré de M. Marche}}
\date{\today}

\begin{document}
	
	\maketitle
	\section{Optimisation en dimension finie}
	\begin{oc-intro}
		Méthode d'évaluation :
		\begin{itemize}
			\item CC noté en CM
			\item 2TPs notés
			\item Examen terminal à 40\%
		\end{itemize}
	\end{oc-intro}
	
	\begin{oc-notation}\,
		On considère un espace vectoriel normé de dimension $n$ noté $(E, ||\cdot||)$ et $U$ ouvert de $E$. On considère une fonction $f\colon U\to \bb R$. Dans la pratique, $E$ sera égal à $\bb R^n$. 
		
		Soit $x\in U$, on note $f'(x)$ la différentielle (qu'on appellera plus simplement "dérivée") de $f$ en $x$. 
		
		On a donc, pour tout $h\in E$ tel que $||h||$ soit assez petit, 
		\[\begin{aligned}
			f(x+h)=f(x)+f'(x)\cdot h+||h||\varepsilon(x, h)
		\end{aligned}\]
		avec $\varepsilon(x, h)\underset{h\to 0}\to 0$
		et $f'(x)\in\scr L(E, \bb R)$.
		
		Avec cette notation, si $f$ est dérivable en $x$, alors $f$ admet des dérivées partielles en $x$ dans toutes les directions, et si $(e_1,\dots,e_n)$ est une base de $E$, on note "$\partial_i f(x)$" ou encore $\frac{\partial f}{\partial x_i}(x)$" la dérivée partielle de $f$ par rapport à la $i$-ème variable. On a alors
		
		\[\begin{aligned}
			\partial f(x)=f'(x)\cdot e_i\qquad i=1,\dots n
		\end{aligned}\]
		
		Ainsi, pour $h\in E$ tel que $h=\sum_{i=1}^nh_ie_i$; on a
		
		\[\begin{aligned}
			f'(x)\cdot h &= f'(x)\cdot\left(\sum_{i=1}^nh_ie_i\right)\\
			&=\sum_{i=1}^n h_i f'(x) e_i\\
			&=\sum_{i=1}^{n} h_i\partial f(x)
		\end{aligned}\]
		
		De même, si $x\mapsto f(x)$ est dérivable en $x$, on note $f''(x)\in\scr L(E;\scr L(E, \bb R))$ cette dérivée seconde et on considère $f''(x)$ comme une forme bilinéaire 
		
		\[\begin{aligned}
			f''(x)\in\scr L(E\times E,\bb R)
		\end{aligned}\]
	\end{oc-notation}
	
	
	
	Avec ces notations, le théorème fondamental de l'analyse (TTA) peut s'énoncer ainsi :
	
	\begin{no-num-theorem}
		Soit $f\in\scr C'(U, \bb R)$. Alors pour tout $(x, y)\in U$ tel que $\forall t\in\ff{0, 1}, x+t(y-x)\in U$, on a
			\[\begin{aligned}
				f(y)=f(x) + \int_0^1f'(x+t(y-x))\cdot(y-x)dt
			\end{aligned}\]	
	\end{no-num-theorem}

	\begin{oc-young}
		Soit $f\in \scr C^2(U, \bb R), x\in U$. Alors il existe un voisinage $\nu$ de $x$ tel que pour tout $h\in \nu$
		
		\[\begin{aligned}
			f(x+h)=f(x)+f'(x)\cdot h+\frac12 f''(x)\cdot(h,h)+ o(||h||^2)
		\end{aligned}\]
		
		Bien entendu, cette expression peut aussi se formuler ainsi :
		\[\begin{aligned}
			f(x+h)=f(x)&+\sum_{i=1}^n\partial_i f(x)h_i\\&+\frac12\sum_{i,j=1}^n\partial_{i, j}^2f(x)h_ih_j\\&+||h||^2\varepsilon (h)\\
		\end{aligned}\]
		avec $\varepsilon(h)\underset{||h||\to 0}\to 0$, de manière a bien mettre en évidence la linéarité de la dérivée et la bilinéarité de la dérivée seconde.
		
		En notant $\nabla f(x)$ le gradient de $f$ évalué en $x$, et $\nabla^2 f(x)$ la matrice Hessienne de $f$ évaluée en $x$, on a :
			\[\begin{aligned}
				f(x+h)=f(x)+\nabla f(x)h+\frac12\prescript{T}{}{h} \nabla^2f(x)\cdot h+ o(||h||^2)
			\end{aligned}\]
	\end{oc-young}
	
	\begin{no-num-definition}
		Soit $f\colon U\to \bb R$ de classe $\scr C^1$. Alors pour tout $a\in U$, il existe un unique vecteur, noté $\nabla f(a)$ tel que pour tout $h\in E$
		\[\begin{aligned}
			f'(a)\cdot h=\langle\nabla f(a), h\rangle
		\end{aligned}\]
		
		où $\langle\cdot, \cdot\rangle $ désigne le produit scalaire canonique sur $\bb R^n$ (qui peut être noté aussi avec $\cdot$ mais dans ce cas attention aux confusions). C'est le \defemph{gradient} de $f$.
	\end{no-num-definition}
	
	\begin{rappel}
		Dans une base orthonormée, on a
		\[\begin{aligned}
			\nabla f(a)=\sum_{i=1}^n\partial_i f(a)e_i
		\end{aligned}\]
	\end{rappel}
	
	
	\subsection{Résultats d'existence}
	
	Un outil fondamental à la compacité
	
	\begin{oc-theorem}
		Soit $K$ un compact de $\bb R^n$ et $f\colon K\to \bb R$ une fonction continue. Alors $f$ est bornée et atteint ses bornes :
		
			\[\begin{aligned}
				\sup_{x\in K}|f(x)|<+\infty
			\end{aligned}\]
		
		et il existe $\underline{x}\in K$ et $\ol x\in K$ tels que 
			\[\begin{aligned}
				f(\underline x)&= \inf_{x\in K}f(x)=\min_{x\in K}f(x)\\
				f(\ol x)&= \sup_{x\in K}f(x)=\max_{x\in K}f(x)\\
			\end{aligned}\]
	\end{oc-theorem}

	\begin{myproof}
		Ce résultat à été démontré dans le cours de topologie / analyse fonctionnelle. 
		
		Puisque $f$ est continue, $f(K)$ est une partie compacte de $\bb R$, c'est à dire une partie fermée et bornée de $\bb R$. Ainsi on a
		\[\begin{aligned}
			-\infty<\inf f(K)\le \sup f(k)<+\infty
		\end{aligned}\]
		et puisque $f(K)$ est fermée et que $\inf f(k)$ et $\sup f(k)$ sont adhérents à $f(K)$, on a
			\[
				\inf f(K)=\min f(K)\in f(E)
			\]
		et 
			\[
			\sup f(K)=\max f(K)\in f(E)
			\]
	\end{myproof}
	\begin{oc-definition}
		Soit $f\colon\bb R^n\to \bb R$. On dit que $f$ est \defemph{coercive} si $f(x)\to+\infty$ lorsque $||x||\to+\infty$.
		
	\end{oc-definition}
	\begin{oc-theorem}
		Soit $f\colon\bb R^n\to\bb R$ continue et coercive. Alors $f$ est minorée et atteint son minimum.
		
	\end{oc-theorem}

	\begin{oc-proof}
		Posons $A=f(0)+1$.
		
		Puisque $f$ est coercive, il existe $\alpha>0$ tel que
			\[\begin{aligned}
				\forall x\in\bb R^n,||x||\ge\alpha\Longrightarrow f(x)\ge f(0)+1
			\end{aligned}\]
		
		La boule $\ol B(0, \alpha)$ est un fermé borné de $\bb R^n$ donc un compact de $\bb R^n$ et $\restr f{\ol B(0, \alpha)}$ est continue.
		
		D'après le Théorème 1.1.1, $f$ est minorée sur $\ol B(0, \alpha)$ et atteint son minimum en un certain $x_0\quad(\forall x\in \ol B(0, \alpha), f(x)\ge f(x_0))$
		
		Ainsi, soit $x\in \bb R^n$
		\begin{enumerate}[a)]
			\item si $x\in \ol B(0, \alpha)$, alors $f(x)\ge f(x_0)$
			\item $x\notin \ol B(0, \alpha)$, alors $||x||>\alpha$ et donc $f(x)\ge f(0)+1$ et $f(x)\ge f(x_0)+1>f(x_0)$ puisque $0\in \ol B(0, \alpha)$
		\end{enumerate}
	
		Ainsi $\forall x\in\bb R^n,f(x)\ge f(x_0)$ et $x_0$ est bien le minimum de $f$ sur $\bb R^n$
		
	\end{oc-proof}

	\begin{oc-remark}
		Ce dernier résultat peut être généralisé, sous les même hypothèses, au cas d'une fonction $f\colon K\to\bb R$ avec $K$ fermé de $\bb R^n$.
		
	\end{oc-remark}

	\subsection{Caractérisation des extremas sans contraintes}
	
	Un outil fondamental : le calcul différentiel.
	
	\begin{oc-theorem}
		Soit $U\sub \bb R^n$ ouvert et $f\colon U\to\bb R$ de classe $\scr C^1$. Si $x_0\in U$ est extremum local de $f$ sur $U$ alors on a $f'(x_0)=0$ $($ou $\nabla f(x_0)=0)$
		
	\end{oc-theorem}

	\begin{oc-proof}
		Rappelons ce qu'il se passe pour une fonction $\varphi\colon I\sub \bb R\to\bb R$ qui admet par exemple un maximum local en $0\in I$.
		
		On a d'une part $\varphi'(0)=\lim\limits_{x\to0^+}\frac{\varphi(x)-\varphi(0)}x\le 0$
		car $x>0$ et $\varphi(x)-\varphi(0)\le 0$
		
		et d'autre part $\varphi'(0)=\lim\limits_{x\to0^-}\frac{\varphi(x)-\varphi(0)}x\ge 0$ car $x<0$ et $\varphi(x)-\varphi(0)\le 0$
		
		Dans le cas $E=\bb R^n$, supposons que $f$ admet un maximum local en $x_0\in U$. Soit $e_i$ un vecteur de base.
		
		On sait que $\partial_i f(x_0)=f'(x_0)\cdot e_i=\varphi_{e_i}'(0)$ avec $\varphi_{e_i}(t)=f(x_0+te_i)$
		
		(où on remarque que $t\in\oo{-\delta,\delta})$ puisque $U$ est ouvert et $x_0\in U$)
		
		Puisque $f$ admet un maximum local en $x_0$, il existe $r>0$ tel que
		\[\begin{aligned}
			\forall x\in B(x_0, r),\quad f(x)\le f(x_0)
		\end{aligned}\]
	
		Soit $h\in\bb R^n$ tel que $||h||\le r$ alors
		
		\[
		f(x_0+h)\le f(x_0)
		\]
		
		et en particulier
		
		\[\begin{aligned}
			|t|\le r&\Longrightarrow f(x_0+t e_i)\le f(x_0)\\
			&\Longrightarrow\varphi_{e_i}'(0)=0
		\end{aligned}\]
	
		Ainsi, toutes les dérivées partielles de $f$ sont nulles en $x_0$ et donc $f'(x_0)=0$
		
	\end{oc-proof}
	\begin{oc-remark}
		Ce résultat est bien entendu faux si $U$ n'est pas ouvert :
			\[\begin{aligned}
				f\colon\ff{0, 1}&\to\ff{0, 1}\quad\text{est }\scr C^\infty\\
				x&\to x
			\end{aligned}\]
		0 est le minimum sur $\ff{0, 1}$, pourtant $f'(0)=1$.
	\end{oc-remark}
	\begin{oc-definition}
		Soit $f\colon U\to\bb R$ et $a\in U$. $a$ est un \defemph{point critique} si au moins une des conditions suivantes est satisfaite :
		\begin{itemize}
			\item $f'(a)=0$
			\item $\nabla f(a)=0$
			\item $\partial_i f(a)=0$ pour $i\in\llbracket1,n\rrbracket$
		\end{itemize}
		
	\end{oc-definition}
	\begin{oc-theorem}\label{thm:1.2.4}
		Soit $U\sub\bb R^n$ ouvert et $f\colon U\to\bb R$ de classe $\scr C^2$.
		
		Si $x_0\in U$ est minimum local de $f$ sur $U$, alors
		\begin{center}
			$f'(x_0)=0$ et $f''(x_0)$ est positive
		\end{center}
		
		Au sens des formes bilinéaires symétriques cela donne 
			\[\begin{aligned}
				\forall \xi\in\bb R^n,f''(x_0)\cdot(\xi,\xi)\ge 0
			\end{aligned}\]
	\end{oc-theorem}
	\begin{myproof}
		Soit $x_0\in U$ et $h\in\bb R^n$. Pour tout $t\in\bb R$ assez petit, on a
			\[\begin{aligned}
				f(x_0+th)-f(x_0)\ge 0
			\end{aligned}\]
		Or, d'après Taylor, on a
			\[\begin{aligned}
				f(x_0+th)-f(x_0)=\frac12 f''(x_0)\cdot(th,th)+\underset{t\to 0}o(t^2)
			\end{aligned}\]
		d'où
			\[\begin{aligned}
				\frac1{t^2}(f(x_0+th)-f(x_0))=\frac12f''(x_0)(h,h)+\underset{t\to 0}o(1)
			\end{aligned}\]
		et donc
			\[\begin{aligned}
				\frac1{t^2}(f(x_0+th)-f(x_0))\underset{t\to0}\to \frac12f''(x_0)(h,h)
			\end{aligned}\]
		Ainsi, on a bien
			\[\begin{aligned}
				\forall h\in\bb R^n,f''(x_0)\cdot(h,h)\ge 0
			\end{aligned}\]
	\end{myproof}
	\begin{oc-remark}
		La réciproque est fausse :
		
		Soit $f\colon\bb R^2\to\bb R$ telle que $f(x,y)=x^2-y^4$. On a
			\[\begin{aligned}
				\nabla f(x,y)=
					\begin{pmatrix*}
						2x\\
						-4y^3
					\end{pmatrix*}
				\qquad \text{et}\qquad \nabla^2f(x,y)=
					\begin{pmatrix*}
						2&0\\
						0&-12y^2
					\end{pmatrix*}
			\end{aligned}\]
		
		On a alors 
			\[\begin{aligned}
				\nabla f(0,0)=0\qquad\text{et}\qquad\nabla^2f(0,0)=
					\begin{pmatrix*}
						2&0\\
						0&0
					\end{pmatrix*}
			\end{aligned}\]
		Ainsi, $\nabla^2f(0,0)\ge0$. Pourtant $(0,0)$ n'est pas un extremum de $f$.
		
	\end{oc-remark}
	
	\begin{oc-remark}
		Ces deux caractérisations sont des conditions nécessaires pour que $x_0$ soit un extremum (mais non suffisantes..)
		
	\end{oc-remark}
	
	\begin{oc-remark}
		Il existe bien entendu un résultat "symétrique" du \myref{thm:1.2.4}{Théorème 1.2.4}:
		\begin{no-num-theorem}
			Si $x_0$ est un \defemph{maximum local} alors 
				\[\begin{aligned}
					f''(x_0)\cdot (h,h)\le 0,\quad\forall h\in\bb R^n
				\end{aligned}\]
			
		\end{no-num-theorem}
		
	\end{oc-remark}
	
	\begin{oc-theorem}
		Soit $U\sub \bb R^n$ ouvert et $f\colon U\to\bb R$ de classe $\scr C^2$.
		
		Soit $x_0\in U$ tel que $f'(x_0)=0$, alors :
		\begin{enumerate}[label=$(\roman*)$]
			\item Si $f''(x_0)$ est \defemph{définie positive}, alors $x_0$ est \defemph{minimum local strict} de $f$.
			\item Si $f''(x_0)$ est \defemph{définie négative}, alors $x_0$ est \defemph{maximum local strict} de $f$.
			\item si $f''(x_0)$ a des valeurs propres non nulles de signe différent alors $x_0$ n'est pas un extremum.
			
			On est alors en présence d'un \defemph{point-selle} (ou "col").
			
			\item si certaines valeurs propres sont nulles on ne peut pas conclure sans effectuer une étude locale au voisinage des points critiques.
		\end{enumerate}
		
	\end{oc-theorem}
	
	\begin{oc-remark}
		La terminologie "définie positive" signifie, au choix, l'une des définitions équivalents suivantes
			\begin{enumerate}[label=$(\roman*)$]
				\item $\forall h\in \scr B(0, r),f''(x_0)\cdot (h,h)>0$
				
				\item $f''$ est positive et non dégénérée.
				
				\item $\spr(\nabla^2f(x_0))\sub \bb R_+^*\quad$(on rappelle que $\spr$ correspond au spectre réel)
			\end{enumerate}
			
		La terminologie "définie négative" se déduit immédiatement.
		
	\end{oc-remark}
	\begin{myproof}
		Reprenons la formule de Taylor Young à l'ordre 2 pour un point critique :
			\[\begin{aligned}
				\forall h\in\scr B(0, r),f(x_0+h)-f(x_0)=\frac12f''(x_0)\cdot(h,h)+o(\nn h^2)
			\end{aligned}\]
		\begin{enumerate}[label=$(\roman*)$]
			\item Puisque $f''(x_0)$ est définie positive, on a
				\[\begin{aligned}
					\alpha\nn h^2\le f''(x_0)\cdot (h, h)\le \beta \nn h^2
				\end{aligned}\]
			où 
			\begin{center}
				$\alpha=\min\{\lambda\}_{i=1}^d>0\qquad$et$\qquad \beta=\max\{\lambda\}_{i=1}^d>0$
			\end{center}
			Ainsi, il existe $r>0$ tel que
				\[\begin{aligned}
					\forall h\in \scr B(0, r)\setminus\{0\},f(x_0+h)-f(x_0)>0
				\end{aligned}\]
			et $x_0$ est donc minimum local strict.
			
			\item On peut appliquer la même méthode pour $f''(x_0)$ définie négative.
			
			\item On suppose que $f''(x_0)\cdot(h,h)$ prend des valeurs strictement positives et strictement négatives. Ainsi, $x_0$ n'est pas un extremum local. On est en présence d'un "point selle".
			
			\item Si certaines valeurs propres sont nulles, on ne peut pas conclure sur la nature de $x_0$ sans effectuer d'étude locale.
		\end{enumerate}
		
	\end{myproof}
	\begin{oc-remark}
		Ces caractérisations peuvent s'étendre sans problème aux dérivées d'ordre supérieures, lorsqu'elles existent.
		
	\end{oc-remark}
	
	\begin{oc-remark}
		Méthode de recherche d'extremas libres
		
		Voir TD2 et 3.
		
	\end{oc-remark}
	\newpage
	\subsection{Convexité : définitions et caractérisations}
	
	\begin{oc-definition}
		Soit $U$ une partie de $\bb R^n$. On dit que $U$ est \defemph{convexe} si
			\[\begin{gathered}
				\forall(x,y)\in U\times U,\forall t\in\ff{0, 1},\\
				tx+(1-t)y\in U
			\end{gathered}\]
		
	\end{oc-definition}
	
	\begin{oc-definition}
		Soit $U$ une partie convexe de $\bb R^n$ et $f\colon U\to \bb R$. 
		
		On dit que $f$ est \defemph{convexe} si 
			\[\begin{gathered}
				\forall(x,y)\in, U\times U,\forall t\in\ff{0, 1},\\
				f(tx+(1-t)y)\le tf(x=+(1-t)f(y))
			\end{gathered}\]
			
		On dit que $f$ est \defemph{strictement convexe} si 
			\[\begin{gathered}
				\forall(x,y)\in, U\times U,\forall t\in\ff{0, 1},\\
				f(tx+(1-t)y)< tf(x=+(1-t)f(y))
			\end{gathered}\]
	\end{oc-definition}
	
	\begin{oc-proposition}
		Soit $U$ un ouvert convexe de $\bb R^n$ et $f\colon U\to \bb R$ de classe $\scr C^1$.
		
		On a $f$ convexe si et seulement si 
			\[\begin{aligned}
				\forall(u,v)\in U\times U,f(v)\ge f(u)+f'(u)\cdot(v-u)
			\end{aligned}\]
			
		De plus, on a $f$ strictement convexe si et seulement si
			\[\begin{aligned}
				\forall(u,v)\in U\times U,f(v)> f(u)+f'(u)\cdot(v-u)
			\end{aligned}\]
		
	\end{oc-proposition}
	
	\begin{myproof}
		Supposons $f$ convexe sur $U$. Soit $(x,y)\in U\times U$ et $t\in\oo{0, 1}$. On a
			\[\begin{aligned}
				f(ty+(1-t)x)&=f(x+t(y-x))\\
				&\le tf(y)+(1-t)f(x)\\
				&\le f(x)+t(f(y)-f(x))
			\end{aligned}\]
		d'où
			\[\begin{aligned}
				\forall t\in\oo{0, 1},\frac1t(f(x+t(y-x))-f(x))\le f(y)-f(x)
			\end{aligned}\]
		En faisant tendre $t$ vers 0, on obtient
			\[\begin{aligned}
				f'(x)\cdot(y-x)\le f(y)-f(x)
			\end{aligned}\]
			
		Réciproquement, supposons que
			\[\begin{aligned}
				\forall (x,y)\in U\times U,f(y)\ge f(x)+f'(x)\cdot(y-x)
			\end{aligned}\]
		Soient $(u,v)\in U\times U$ et $t\in\oo{0,1}$.
		
		On pose $x=tu+(1-t)v$ et $y=u$. On a alors
			\[\label{eq1}
			f(u)\ge f(tu+(1-t)v+f'(tu+(1-t)v)\cdot((1-t)(u-v))\tag{1}
			\]
			
		On pose $x=tu+(1-t)v$ et $y=v$. On a alors
			\[\label{eq2}
			f(u)\ge f(tu+(1-t)v+f'(tu+(1-t)v)\cdot(t(v-u))\tag{2}
			\]
		La combinaison linéaire $t\hyperref[eq1]{(1)}+(1-t)\hyperref[eq2]{(2)}$ donne alors 
			\[\begin{aligned}
				tf(u)+(1-t)f(v)\ge f(tu+(1-t)v)
			\end{aligned}\]
		Donc $f$ est convexe.
		
		En appliquant le même raisonnement avec des inégalités strictes on peut montrer que si
			\[\begin{aligned}
				f(y)>f(x)+f'(x)\cdot(y-x)
			\end{aligned}\]
		alors $f$ est strictement convexe.
		
		Enfin, supposons $f$ strictement convexe.
		
		On considère 
			\[\begin{aligned}
				x,y\in U,x\ne y,t\in\oo{0, 1},w=tx+(1-t)y
			\end{aligned}\]
		On a $f$ convexe par hypothèse donc, d'après ce qui précède, on a
			\[\begin{aligned}
				f(w)-f(x)\ge f'(x)\cdot (w-x)
			\end{aligned}\]
		Or 
			\[\begin{gathered}
				f(w)< tf(x)+(1-t)f(y)\\
				\text{et }w-x=(1-t)(y-x)
			\end{gathered}\]
		Ainsi, on obtient :
			\[\begin{aligned}
				tf(x)+(1-t)f(y)-f(x)>f'(x)\cdot((1-t)(y-x))
			\end{aligned}\]
		d'où
			\[\begin{aligned}
				(1-t)(f(y)-f(x))>(1-t)f'(x)\cdot(y-x)
			\end{aligned}\]
		et donc
			\[\begin{aligned}
				f(y)>f(x)+f'(x)\cdot(y-x)
			\end{aligned}\]
	\end{myproof}
\end{document}
